rag_search_task:
  description: >
    If a user query "{query}" is provided:
      • Perform a semantic search in the vector database to retrieve relevant documents and context.

    Requirements:
    • Search the vector store for top-15 relevant results for {query}.
    • Return results as a simple list of document texts (strings) for easy use by other agents or tasks.
  expected_output: >
    A JSON object containing:
      search_results: list of top-15 document texts (strings only, no metadata)
  agent: rag_agent
  
point_selection_task:
  description: >
    Evaluate the relevance of the following context sources for the query: "{query}"
    
    Context Sources:
    1. RAG Result: [Use the output from the previous RAG search task]
    
    For each source, determine:
    - Is it relevant to answering the query? (yes/no)
    - Confidence score of relevance (0-1)
    - Key information that should be included in the final response
    - What information should be filtered out as irrelevant
    
    Note: If a source has ERROR status, it should not be included in relevant_sources, but mention it in the reasoning.
    
    Return only the relevant context that should be used for generating the final response.
    
    IMPORTANT: Your response must strictly follow the provided JSON schema structure.
  expected_output: >
    Assess the relevance and quality of all retrieved context to ensure 
    only useful information is passed to the synthesizer.
  agent: selector_agent

synthesis_task:
  description: >
    Combine the relevant information from all sources to generate a clear, concise, 
    and accurate response to the query: "{query}".
    
    Sources may include:
    - RAG search results
    
    Ensure the final response:
    - Answers the query accurately
    - Is coherent and well-structured
    - Avoids irrelevant or redundant information
  expected_output: >
    Generate a comprehensive response for the user by integrating the relevant context 
    provided from the sources.
  agent: synthesizer_agent

document_loader_task:
  description: >
    Given a URL "{url}", load the content of the website or document,
    split it into chunks, and optionally store it in a vector database.
    
    Steps:
      1. Access the URL and extract text content.
      2. Split the text into chunks for easier processing.
      3. Persist the chunks to the vector database (if required).
    
    Return:
      - status: success/fail
      - total_chunks: number of chunks created
      - vector_store_status: success/fail (if persisted)
  expected_output: >
    JSON object containing ingestion status, number of chunks created, and persistence status.
  agent: doc_loader_agent